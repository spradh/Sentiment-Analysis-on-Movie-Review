{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import plotly.tools as pytools\n",
    "import cred\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytools.set_credentials_file(username=cred.username, api_key=cred.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.tsv', sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>156060.000000</td>\n",
       "      <td>156060.000000</td>\n",
       "      <td>156060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78030.500000</td>\n",
       "      <td>4079.732744</td>\n",
       "      <td>2.063578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45050.785842</td>\n",
       "      <td>2502.764394</td>\n",
       "      <td>0.893832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39015.750000</td>\n",
       "      <td>1861.750000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78030.500000</td>\n",
       "      <td>4017.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>117045.250000</td>\n",
       "      <td>6244.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>156060.000000</td>\n",
       "      <td>8544.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PhraseId     SentenceId      Sentiment\n",
       "count  156060.000000  156060.000000  156060.000000\n",
       "mean    78030.500000    4079.732744       2.063578\n",
       "std     45050.785842    2502.764394       0.893832\n",
       "min         1.000000       1.000000       0.000000\n",
       "25%     39015.750000    1861.750000       2.000000\n",
       "50%     78030.500000    4017.000000       2.000000\n",
       "75%    117045.250000    6244.000000       3.000000\n",
       "max    156060.000000    8544.000000       4.000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 15240)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize tex with scikit learn\n",
    "#Convert a collection of text documents to a matrix of token counts\n",
    "count_vector=CountVectorizer()\n",
    "#Learn the vocabulary dictionary and return term-document matrix.\n",
    "x_df_counts=count_vector.fit_transform(df['Phrase'])\n",
    "x_df_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8791"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector.vocabulary_.get(u\"movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10', '100', '101', '102', '103', '104', '105', '10th', '11']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector.get_feature_names()[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_transformer=TfidfTransformer(use_idf=False).fit(x_df_counts)\n",
    "x_df_tf=tf_transformer.transform(x_df_counts)\n",
    "tfidf_transformer=TfidfTransformer()\n",
    "x_df_tfidf=tfidf_transformer.fit_transform(x_df_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating Training and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = x_df_tfidf[msk]\n",
    "test = x_df_tfidf[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training  Multinomial Naive Bayes Model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "clf_MultinomialNB=MultinomialNB().fit(train, df[msk]['Sentiment'])\n",
    "train_pred_MultinomialNB=clf_MultinomialNB.predict(train)\n",
    "test_pred_MultinomialNB=clf_MultinomialNB.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "print(clf_MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.6311603181581997 \n",
      "Test Accuracy: 0.5897949297594057\n"
     ]
    }
   ],
   "source": [
    "#Model Performance Metrics\n",
    "accuracy_MultinomialNB_train = accuracy_score( df[msk]['Sentiment'],train_pred_MultinomialNB)#TODO\n",
    "accuracy_MultinomialNB_test = accuracy_score( df[~msk]['Sentiment'],test_pred_MultinomialNB)#TODO\n",
    "print (\"Train Accuracy: \",accuracy_MultinomialNB_train,\"\\nTest Accuracy:\",accuracy_MultinomialNB_test)\n",
    "\n",
    "confusion_MultinomialNB_train=confusion_matrix(df[msk]['Sentiment'],train_pred_MultinomialNB)\n",
    "confusion_MultinomialNB_test=confusion_matrix(df[~msk]['Sentiment'],test_pred_MultinomialNB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/60.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make training confusion matrix heat map\n",
    "trace1 = go.Heatmap(z=confusion_MultinomialNB_train, x=[0,1,2,3,4], y=[0,1,2,3,4])\n",
    "data1=[trace1]\n",
    "layout1 = go.Layout(title=\"Multinomial Naive Bayes Confusion Matrix Training\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig1 = go.Figure(data=data1, layout=layout1)\n",
    "py.iplot(fig1, filename='mnb-train-con-heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/62.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making test confusion matrix heat map\n",
    "trace2 = go.Heatmap(z=confusion_MultinomialNB_test, x=[0,1,2,3,4], y=[0,1,2,3,4])\n",
    "data2=[trace2]\n",
    "layout2 = go.Layout(title=\"Multinomial Naive Bayes Confusion Matrix Testing\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig2 = go.Figure(data=data2, layout=layout2)\n",
    "py.iplot(fig2, filename='mnb-test-con-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (Linear Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm \n",
    "\n",
    "clf_svm_Linear = svm.LinearSVC().fit(train, df[msk]['Sentiment'])\n",
    "train_pred_svm_linear=clf_svm_Linear.predict(train)\n",
    "test_pred_svm_linear=clf_svm_Linear.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    }
   ],
   "source": [
    "print(clf_svm_Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.7229145849154642 \n",
      "Test Accuracy: 0.6479896657516551\n"
     ]
    }
   ],
   "source": [
    "#Model Performance Metrics\n",
    "accuracy_svm_linear_train= accuracy_score( df[msk]['Sentiment'],train_pred_svm_linear)\n",
    "accuracy_svm_linear_test= accuracy_score( df[~msk]['Sentiment'],test_pred_svm_linear)#\n",
    "print (\"Train Accuracy: \",accuracy_svm_linear_train,\"\\nTest Accuracy:\",accuracy_svm_linear_test)\n",
    "\n",
    "confusion_svm_linear_train=confusion_matrix(df[msk]['Sentiment'],train_pred_svm_linear)\n",
    "confusion_svm_linear_test=confusion_matrix(df[~msk]['Sentiment'],test_pred_svm_linear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/64.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make training confusion matrix heat map\n",
    "trace1 = go.Heatmap(z=confusion_svm_linear_train, x=[0,1,2,3,4], y=[0,1,2,3,4])\n",
    "data1=[trace1]\n",
    "layout1 = go.Layout(title=\"SVM Confusion Matrix Training\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig1 = go.Figure(data=data1, layout=layout1)\n",
    "py.iplot(fig1, filename='svm-train-con-heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/66.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making test confusion matrix heat map\n",
    "trace2 = go.Heatmap(z=confusion_svm_linear_test, x=[0,1,2,3,4], y=[0,1,2,3,4])\n",
    "data2=[trace2]\n",
    "layout2 = go.Layout(title=\"SVM Confusion Matrix Testing\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig2 = go.Figure(data=data2, layout=layout2)\n",
    "py.iplot(fig2, filename='svm-test-con-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "clf_mlp = MLPClassifier(solver='lbfgs',activation='logistic', \n",
    "                        alpha=1e-5,hidden_layer_sizes=(2), random_state=1)\n",
    "clf_mlp=clf_mlp.fit(train, df[msk]['Sentiment'])\n",
    "train_pred_mlp=clf_mlp.predict(train)\n",
    "test_pred_mlp=clf_mlp.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='logistic', alpha=1e-05, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=2, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(clf_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.6946400735441065 \n",
      "Test Accuracy: 0.6481511383820442\n"
     ]
    }
   ],
   "source": [
    "#Model Performance Metrics\n",
    "accuracy_mlp_train= accuracy_score( df[msk]['Sentiment'],train_pred_mlp)\n",
    "accuracy_mlp_test= accuracy_score( df[~msk]['Sentiment'],test_pred_mlp)#\n",
    "print (\"Train Accuracy: \",accuracy_mlp_train,\"\\nTest Accuracy:\",accuracy_mlp_test)\n",
    "\n",
    "confusion_mlp_train=confusion_matrix(df[msk]['Sentiment'],train_pred_mlp)\n",
    "confusion_mlp_test=confusion_matrix(df[~msk]['Sentiment'],test_pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/68.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make training confusion matrix heat map\n",
    "trace1 = go.Heatmap(z=confusion_mlp_train, x=[0,1,2,3,4], y=[0,1,2,3,4])\n",
    "data1=[trace1]\n",
    "layout1 = go.Layout(title=\"Neural Network Confusion Matrix Training\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig1 = go.Figure(data=data1, layout=layout1)\n",
    "py.iplot(fig1, filename='nn-train-con-heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/70.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making test confusion matrix heat map\n",
    "trace2 = go.Heatmap(z=confusion_mlp_test, x=[0,1,2,3,4], y=[0,1,2,3,4])\n",
    "data2=[trace2]\n",
    "layout2 = go.Layout(title=\"Neural Network Confusion Matrix Testing\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig2 = go.Figure(data=data2, layout=layout2)\n",
    "py.iplot(fig2, filename='nn-test-con-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "\n",
    "clf_dtrees=tree.DecisionTreeClassifier().fit(train, df[msk]['Sentiment'])\n",
    "train_pred_dtrees=clf_dtrees.predict(train)\n",
    "test_pred_dtrees=clf_dtrees.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print(clf_dtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9528278508333666 \n",
      "Test Accuracy: 0.580461811722913\n"
     ]
    }
   ],
   "source": [
    "#Model Performance Metrics\n",
    "accuracy_dtrees_train= accuracy_score( df[msk]['Sentiment'],train_pred_dtrees)\n",
    "accuracy_dtrees_test= accuracy_score( df[~msk]['Sentiment'],test_pred_dtrees)#\n",
    "print (\"Train Accuracy: \",accuracy_dtrees_train,\"\\nTest Accuracy:\",accuracy_dtrees_test)\n",
    "\n",
    "confusion_dtrees_train=confusion_matrix(df[msk]['Sentiment'],train_pred_dtrees)\n",
    "confusion_dtrees_test=confusion_matrix(df[~msk]['Sentiment'],test_pred_dtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/72.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make training confusion matrix heat map\n",
    "trace1 = go.Heatmap(z=confusion_dtrees_train, x=[0,1,2,3,4], y=[0,1,2,3,4])\n",
    "data1=[trace1]\n",
    "layout1 = go.Layout(title=\"Decision Trees Confusion Matrix Training\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig1 = go.Figure(data=data1, layout=layout1)\n",
    "py.iplot(fig1, filename='dt-train-con-heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/74.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making test confusion matrix heat map\n",
    "trace2 = go.Heatmap(z=confusion_dtrees_test, x=[0,1,2,3,4], y=[0,1,2,3,4])\n",
    "data2=[trace2]\n",
    "layout2 = go.Layout(title=\"Decision Trees Confusion Matrix Testing\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig2 = go.Figure(data=data2, layout=layout2)\n",
    "py.iplot(fig2, filename='dt-test-con-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_forest=RandomForestClassifier(max_depth=None,random_state=0).fit(train, df[msk]['Sentiment'])\n",
    "train_pred_forest=clf_forest.predict(train)\n",
    "test_pred_forest=clf_forest.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(clf_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9359766577401175 \n",
      "Test Accuracy: 0.6261585661230421\n"
     ]
    }
   ],
   "source": [
    "#Model Performance Metrics\n",
    "accuracy_forest_train= accuracy_score( df[msk]['Sentiment'],train_pred_forest)\n",
    "accuracy_forest_test= accuracy_score( df[~msk]['Sentiment'],test_pred_forest)#\n",
    "print (\"Train Accuracy: \",accuracy_forest_train,\"\\nTest Accuracy:\",accuracy_forest_test)\n",
    "\n",
    "confusion_forest_train=confusion_matrix(df[msk]['Sentiment'],train_pred_forest)\n",
    "confusion_forest_test=confusion_matrix(df[~msk]['Sentiment'],test_pred_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/76.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make training confusion matrix heat map\n",
    "trace1 = go.Heatmap(z=confusion_forest_train, x=[0,1,2,3,4], y=[0,1,2,3,4])\n",
    "data1=[trace1]\n",
    "layout1 = go.Layout(title=\"Random Forest Confusion Matrix Training\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig1 = go.Figure(data=data1, layout=layout1)\n",
    "py.iplot(fig1, filename='rf-train-con-heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/82.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make testing confusion matrix heat map\n",
    "trace1 = go.Heatmap(z=confusion_forest_test, x=[0,1,2,3,4], y=[0,1,2,3,4])\n",
    "data1=[trace1]\n",
    "layout1 = go.Layout(title=\"Random Forest Confusion Matrix Training\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig1 = go.Figure(data=data1, layout=layout1)\n",
    "py.iplot(fig1, filename='rf-test-con-heatmap')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
