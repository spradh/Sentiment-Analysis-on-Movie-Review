{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Project below is uses the Rotten Totato Movie Review Data Set from Kaggle to create an Sentiment Analysis Model. The creators of the dataset used Amazon's Mechanical Turk to create a finely labeled dataset which is ofent used as a benchmark dataset for Sentiment Analysis. \n",
    "\n",
    "The data set contains movie reviews that are separated into phrases. Each observation in the data set is a phrase that is associated to a Sentence Id and has a Sentiment associated. Sentiments are as follows : \n",
    "\n",
    "    0 - negative\n",
    "    1 - somewhat negative\n",
    "    2 - neutral\n",
    "    3 - somewhat positive\n",
    "    4 - positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Project starts with importing all the necessary libraries to preprocess and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd # Gives us the data structure and operations for easy manipulation of data\n",
    "import numpy as np  # Allows us to randomly assign training and test observations\n",
    "from sklearn.feature_extraction.text import TfidfTransformer #To conduct Term Frequency Inverse Document Frequency Tranformation\n",
    "from sklearn.feature_extraction.text import CountVectorizer #To create text document matrix\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix # Provides libraries to calculate accuracy and confusion matrix\n",
    "import plotly.tools as pytools # Allows user to connect to their plotly account\n",
    "import cred # provides credentials for the plotly account\n",
    "import plotly.plotly as py # Allows us to plot graphs using plotly\n",
    "import plotly.graph_objs as go # creates graphs using the plotly library\n",
    "from nltk.stem import PorterStemmer # Provides root for words\n",
    "from nltk.corpus import stopwords # Provides stop words for the english language\n",
    "from nltk.tokenize import word_tokenize # Helps tokenize phrases to words\n",
    "import re # helps program parse strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to the Plotly Server "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We connect to the plotly server using the set_credentials_file function fromthe plotly.tools module. We pull the username and api_key credentials from the cred module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pytools.set_credentials_file(username=cred.username, api_key=cred.api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data into Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the read_csv function to load the train.tsv data file into python. The program runs some cursory check of the data using the head() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the Kaggle instructions, the target variable in the Sentiment column had 5 non overlapping categories. We check this using the unique operator which returns 5 distinct values for the Sentiment columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words and Stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us talk about stop words. Stop words are words very commonly used that do not add much meaning to the sentence and are used primarily use for grammatical puposes like \"is\", \"the\", and \"a\". We want to remove these words so that we can denoise our data set and create better models. \n",
    "\n",
    "Secondly, we often use different words to say the same thing. When someone describles riding a horse, they can use the words \"ride\", \"riding\", \"rode\", \"ridden\", etc. that all stem from the same word \"ride\". Stemming achieve exactly this and helps reduces the dimentionality of data set and in NLP terms helps create a more normalized data set.\n",
    "\n",
    "So the function stop_and_stem below helps us remove stop words and find stems for remaining words. It achieves this by: \n",
    "1. converting the phrase to lower case\n",
    "2. tokenizing a given phrase into words\n",
    "3. removing words that fall in the stop_words set\n",
    "4. using the ps.stem command to convert words to their respective roots\n",
    "\n",
    "I added another feature to the function below that removes all punctuation's from the resulting processed phrase and join the dataset back together using the join method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words(\"english\"))\n",
    "ps=PorterStemmer()\n",
    "\n",
    "#removes stop words/ digits/ puntuations and stemms the words\n",
    "def stop_and_stem(phrase):\n",
    "    global stop_words, ps\n",
    "    phrase=[ps.stem(word) for word in word_tokenize(phrase.lower()) if not word in stop_words]\n",
    "    phrase=[re.sub(r'[^\\w\\s]','',word) for word in phrase]\n",
    "    return \" \".join(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the apply methods in the Phrase column of our dataset and pass the stop_and_stem function to process the phrase information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Phrase'] = df['Phrase'].apply(stop_and_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the command below, you will see that the words in the phrases have been reduced to their stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>seri escapad demonstr adag good goos also good...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>seri escapad demonstr adag good goos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>seri</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>seri</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  seri escapad demonstr adag good goos also good...   \n",
       "1         2           1               seri escapad demonstr adag good goos   \n",
       "2         3           1                                               seri   \n",
       "3         4           1                                                      \n",
       "4         5           1                                               seri   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Phrase Column to Matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first step we need to take after the data has been stemmed and the stop words have been removed is that we have to convert the phrases into a matrix format with token counts. We can achieve this using the CountVectorizer class from the sklearn.feature_extraction.text module. \n",
    "\n",
    "Once we create the CountVectorizer object count_vector, we use the fit_transform method to feed the Phrase column and assign the resulting matrix to the x_df_counts. x_df_counts will have the same number of rows as the number of observations in our original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 11856)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize tex with scikit learn\n",
    "#Convert a collection of text documents to a matrix of token counts\n",
    "count_vector=CountVectorizer()\n",
    "#Learn the vocabulary dictionary and return term-document matrix.\n",
    "x_df_counts=count_vector.fit_transform(df['Phrase'])\n",
    "x_df_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to look for the index of any given word stem, you can use the vocabulary_.get() method and pass the word of interest as the argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9133"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns index of words\n",
    "count_vector.vocabulary_.get(\"seri\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an exhaustive list of all the features, you can use the get_feature_names() which will return a list of all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100',\n",
       " '10000',\n",
       " '100minut',\n",
       " '100year',\n",
       " '101',\n",
       " '102minut',\n",
       " '103minut',\n",
       " '104',\n",
       " '105']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector.get_feature_names()[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency- Inverse document Frequency or TFDIF is a term often used in the domain of information retreival. This techniques helps assign a numerical statistic to a words that shows its importance in the document.The tf-idf value is proportional to the ratio of the requency of the word in the phrase and the frequency of the word in entire corpus\n",
    "We initialize the TfidTranformer object tfidf_transformer and using the fit_transform method to generate the the TFDIF statistic for each word in a given phrase in the Phrase column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_transformer=TfidfTransformer()\n",
    "x_df_tfidf=tfidf_transformer.fit_transform(x_df_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating Training and Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start building out models, we need to divid our data set into a training set and a test set. We use a random uniform number generator to divide the data set into an 80:20 training-test ratio.\n",
    "We do this by first setting the random seed to 10 using the random.seed() function. This will help us reporduce our findings. Then, we genrate 156060 draws from a uniform distribution between 0 and 1 and create a bolean array msk where draws less than .8 are labeled as True and otherwise labeled False. We use the newly created msk variable to select observations from x_df_tfidf to assign our training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = x_df_tfidf[msk]\n",
    "test = x_df_tfidf[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the command below, there is an approximate 80-20 split between training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124964, 11856), (31096, 11856))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the models constructed below are divided into 5 distinct sections:\n",
    "1. Classifier: Once the relevant module has been imported, we initial a classifier object. We then use the fit method and pass the training predictors and the corresponding target variables to generate the model. Once the model has been created, we use the predict method to get the training and test predictions.\n",
    "2. Classifier Parameters: We then print the classifier to see the parameters of the model.\n",
    "3. Accuracy and Confusion Matrix: We generate the accuracy and confusion matrix for the training and test set using the accuracy_score and confusion_matrix function from the sklearn.metrics module\n",
    "4. Graph Confusion Matrix for Training Data\n",
    "5. Graph Confusion Matrix for Testig Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training  Multinomial Naive Bayes Model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf_MultinomialNB=MultinomialNB().fit(train, df[msk]['Sentiment'])\n",
    "train_pred_MultinomialNB=clf_MultinomialNB.predict(train)\n",
    "test_pred_MultinomialNB=clf_MultinomialNB.predict(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "print(clf_MultinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy and Confusion Matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.62017861144 \n",
      "Test Accuracy: 0.585477231798\n"
     ]
    }
   ],
   "source": [
    "#Model Performance Metrics\n",
    "accuracy_MultinomialNB_train = accuracy_score( df[msk]['Sentiment'],\n",
    "                                              train_pred_MultinomialNB)#TODO\n",
    "accuracy_MultinomialNB_test = accuracy_score( df[~msk]['Sentiment'],\n",
    "                                             test_pred_MultinomialNB)#TODO\n",
    "print (\"Train Accuracy: \",accuracy_MultinomialNB_train,\"\\nTest Accuracy:\",\n",
    "       accuracy_MultinomialNB_test)\n",
    "\n",
    "confusion_MultinomialNB_train=confusion_matrix(df[msk]['Sentiment'],\n",
    "                                               train_pred_MultinomialNB)\n",
    "confusion_MultinomialNB_test=confusion_matrix(df[~msk]['Sentiment'],\n",
    "                                              test_pred_MultinomialNB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Confusion Matrix for Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/60.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make training confusion matrix heat map\n",
    "trace1 = go.Heatmap(z=confusion_MultinomialNB_train,\n",
    "                    x=[0,1,2,3,4], \n",
    "                    y=[0,1,2,3,4])\n",
    "data1=[trace1]\n",
    "layout1 = go.Layout(title=\"Multinomial Naive Bayes Confusion Matrix Training\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig1 = go.Figure(data=data1, layout=layout1)\n",
    "py.iplot(fig1, filename='mnb-train-con-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Confusion Matrix for Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/62.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making test confusion matrix heat map\n",
    "trace2 = go.Heatmap(z=confusion_MultinomialNB_test,\n",
    "                    x=[0,1,2,3,4], \n",
    "                    y=[0,1,2,3,4])\n",
    "data2=[trace2]\n",
    "layout2 = go.Layout(title=\"Multinomial Naive Bayes Confusion Matrix Testing\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig2 = go.Figure(data=data2, layout=layout2)\n",
    "py.iplot(fig2, filename='mnb-test-con-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (Linear Kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm \n",
    "\n",
    "clf_svm_Linear = svm.LinearSVC().fit(train, df[msk]['Sentiment'])\n",
    "train_pred_svm_linear=clf_svm_Linear.predict(train)\n",
    "test_pred_svm_linear=clf_svm_Linear.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    }
   ],
   "source": [
    "print(clf_svm_Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy and Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.696736660158 \n",
      "Test Accuracy: 0.637992024698\n"
     ]
    }
   ],
   "source": [
    "#Model Performance Metrics\n",
    "accuracy_svm_linear_train= accuracy_score( df[msk]['Sentiment'],\n",
    "                                          train_pred_svm_linear)\n",
    "accuracy_svm_linear_test= accuracy_score( df[~msk]['Sentiment'],\n",
    "                                         test_pred_svm_linear)#\n",
    "print (\"Train Accuracy: \",accuracy_svm_linear_train,\n",
    "       \"\\nTest Accuracy:\",accuracy_svm_linear_test)\n",
    "\n",
    "confusion_svm_linear_train=confusion_matrix(df[msk]['Sentiment'],\n",
    "                                            train_pred_svm_linear)\n",
    "confusion_svm_linear_test=confusion_matrix(df[~msk]['Sentiment'],\n",
    "                                           test_pred_svm_linear)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Confusion Matrix for Training Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/64.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make training confusion matrix heat map\n",
    "trace1 = go.Heatmap(z=confusion_svm_linear_train, \n",
    "                    x=[0,1,2,3,4], \n",
    "                    y=[0,1,2,3,4])\n",
    "data1=[trace1]\n",
    "layout1 = go.Layout(title=\"SVM Confusion Matrix Training\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig1 = go.Figure(data=data1, layout=layout1)\n",
    "py.iplot(fig1, filename='svm-train-con-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Confusion Matrix for Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/66.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making test confusion matrix heat map\n",
    "trace2 = go.Heatmap(z=confusion_svm_linear_test, \n",
    "                    x=[0,1,2,3,4],\n",
    "                    y=[0,1,2,3,4])\n",
    "data2=[trace2]\n",
    "layout2 = go.Layout(title=\"SVM Confusion Matrix Testing\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig2 = go.Figure(data=data2, layout=layout2)\n",
    "py.iplot(fig2, filename='svm-test-con-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "clf_mlp = MLPClassifier(solver='adam',activation='logistic', \n",
    "                        hidden_layer_sizes=(10), \n",
    "                        max_iter=400,random_state=1)\n",
    "clf_mlp=clf_mlp.fit(train, df[msk]['Sentiment'])\n",
    "train_pred_mlp=clf_mlp.predict(train)\n",
    "test_pred_mlp=clf_mlp.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=10, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=400, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(clf_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy and Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.796829486892 \n",
      "Test Accuracy: 0.641658091073\n"
     ]
    }
   ],
   "source": [
    "#Model Performance Metrics\n",
    "accuracy_mlp_train= accuracy_score( df[msk]['Sentiment'],\n",
    "                                   train_pred_mlp)\n",
    "accuracy_mlp_test= accuracy_score( df[~msk]['Sentiment'],\n",
    "                                  test_pred_mlp)#\n",
    "print (\"Train Accuracy: \",accuracy_mlp_train,\n",
    "       \"\\nTest Accuracy:\",accuracy_mlp_test)\n",
    "\n",
    "confusion_mlp_train=confusion_matrix(df[msk]['Sentiment'],\n",
    "                                     train_pred_mlp)\n",
    "confusion_mlp_test=confusion_matrix(df[~msk]['Sentiment'],\n",
    "                                    test_pred_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Confusion Matrix for Training Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/68.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make training confusion matrix heat map\n",
    "trace1 = go.Heatmap(z=confusion_mlp_train,\n",
    "                    x=[0,1,2,3,4], \n",
    "                    y=[0,1,2,3,4])\n",
    "data1=[trace1]\n",
    "layout1 = go.Layout(title=\"Neural Network Confusion Matrix Training\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig1 = go.Figure(data=data1, layout=layout1)\n",
    "py.iplot(fig1, filename='nn-train-con-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Confusion Matrix for Testing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/70.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making test confusion matrix heat map\n",
    "trace2 = go.Heatmap(z=confusion_mlp_test,\n",
    "                    x=[0,1,2,3,4],\n",
    "                    y=[0,1,2,3,4])\n",
    "data2=[trace2]\n",
    "layout2 = go.Layout(title=\"Neural Network Confusion Matrix Testing\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig2 = go.Figure(data=data2, layout=layout2)\n",
    "py.iplot(fig2, filename='nn-test-con-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "\n",
    "clf_dtrees=tree.DecisionTreeClassifier().fit(train,\n",
    "                            df[msk]['Sentiment'])\n",
    "train_pred_dtrees=clf_dtrees.predict(train)\n",
    "test_pred_dtrees=clf_dtrees.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print(clf_dtrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy and Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.865321212509 \n",
      "Test Accuracy: 0.62255595575\n"
     ]
    }
   ],
   "source": [
    "#Model Performance Metrics\n",
    "accuracy_dtrees_train= accuracy_score( df[msk]['Sentiment'],\n",
    "                                      train_pred_dtrees)\n",
    "accuracy_dtrees_test= accuracy_score( df[~msk]['Sentiment'],\n",
    "                                     test_pred_dtrees)\n",
    "print (\"Train Accuracy: \",accuracy_dtrees_train,\n",
    "       \"\\nTest Accuracy:\",accuracy_dtrees_test)\n",
    "\n",
    "confusion_dtrees_train=confusion_matrix(df[msk]['Sentiment'],\n",
    "                                        train_pred_dtrees)\n",
    "confusion_dtrees_test=confusion_matrix(df[~msk]['Sentiment'],\n",
    "                                       test_pred_dtrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Confusion Matrix of Training Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/72.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make training confusion matrix heat map\n",
    "trace1 = go.Heatmap(z=confusion_dtrees_train,\n",
    "                    x=[0,1,2,3,4],\n",
    "                    y=[0,1,2,3,4])\n",
    "data1=[trace1]\n",
    "layout1 = go.Layout(title=\"Decision Trees Confusion Matrix Training\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig1 = go.Figure(data=data1, layout=layout1)\n",
    "py.iplot(fig1, filename='dt-train-con-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Confusion Matrix for Testing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/74.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making test confusion matrix heat map\n",
    "trace2 = go.Heatmap(z=confusion_dtrees_test,\n",
    "                    x=[0,1,2,3,4], \n",
    "                    y=[0,1,2,3,4])\n",
    "data2=[trace2]\n",
    "layout2 = go.Layout(title=\"Decision Trees Confusion Matrix Testing\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig2 = go.Figure(data=data2, layout=layout2)\n",
    "py.iplot(fig2, filename='dt-test-con-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_forest=RandomForestClassifier(max_depth=None,\n",
    "                                  random_state=0).fit(train,\n",
    "                                df[msk]['Sentiment'])\n",
    "train_pred_forest=clf_forest.predict(train)\n",
    "test_pred_forest=clf_forest.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(clf_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy and Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.856942799526 \n",
      "Test Accuracy: 0.634551067661\n"
     ]
    }
   ],
   "source": [
    "#Model Performance Metrics\n",
    "accuracy_forest_train= accuracy_score( df[msk]['Sentiment'],\n",
    "                                      train_pred_forest)\n",
    "accuracy_forest_test= accuracy_score( df[~msk]['Sentiment'],\n",
    "                                     test_pred_forest)#\n",
    "print (\"Train Accuracy: \",accuracy_forest_train,\n",
    "       \"\\nTest Accuracy:\",accuracy_forest_test)\n",
    "\n",
    "confusion_forest_train=confusion_matrix(df[msk]['Sentiment'],\n",
    "                                        train_pred_forest)\n",
    "confusion_forest_test=confusion_matrix(df[~msk]['Sentiment'],\n",
    "                                       test_pred_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Confusion Matrix for Training Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/76.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make training confusion matrix heat map\n",
    "trace1 = go.Heatmap(z=confusion_forest_train, \n",
    "                    x=[0,1,2,3,4], \n",
    "                    y=[0,1,2,3,4])\n",
    "data1=[trace1]\n",
    "layout1 = go.Layout(title=\"Random Forest Confusion Matrix Training\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig1 = go.Figure(data=data1, layout=layout1)\n",
    "py.iplot(fig1, filename='rf-train-con-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Confusion Matrix for Testing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~spradh/82.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make testing confusion matrix heat map\n",
    "trace1 = go.Heatmap(z=confusion_forest_test, \n",
    "                    x=[0,1,2,3,4], \n",
    "                    y=[0,1,2,3,4])\n",
    "data1=[trace1]\n",
    "layout1 = go.Layout(title=\"Random Forest Confusion Matrix Testing\",\n",
    "                xaxis=dict(title='Predicted Sentiment'),\n",
    "                yaxis=dict(title='True Sentiment'))\n",
    "fig1 = go.Figure(data=data1, layout=layout1)\n",
    "py.iplot(fig1, filename='rf-test-con-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the accuracies (training, test) of the above models:\n",
    "    1. Multinomial Naive Bayes: (61.98%, 58.63%)\n",
    "    2. SVM                    : (69.75%, 63.75%)\n",
    "    3. Neural Network         : (79.68%, 64.17%)\n",
    "    4. Decision Trees         : (86.43%, 62.19%)\n",
    "    5. Random Forest          : (85.57%, 63.57%)\n",
    "\n",
    "The Neural Network model had the best test performance overall and a decent training accuracy score.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitation and Improvement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While most of the initial limitations of this project has been mitigated there has not been a significant increase in model performance. May be building recurrent neural networks and incorporating part of speech to the initial data set might be helpful."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
